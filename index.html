<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>PRISM</title>
<link href="./PRISM_files/style.css" rel="stylesheet">
<script type="text/javascript" src="./PRISM_files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./PRISM_files/jquery.js"></script>
</head>

<body>
<div class="content">
  <h1><strong>PRISM: A New Lens for Improved Color Understanding</strong></h1>
  <p id="authors"><span><a href="https://research.google/people/ArjunReddyAkula/"></a></span>
    <a href="https://research.google/people/ArjunReddyAkula/">Arjun R. Akula</a	> 
    <a href="https://www.linkedin.com/in/brendan-driscoll-43104963/">Garima Pruthi</a> 
    <a href="https://scholar.google.com/citations?user=BV2dbjEAAAAJ&hl=en">IInderjit S Dhillon</a> 
    <a href="https://research.google/people/106773/">Pradyumna Narayanao</a> <br>
    <a href="https://zjia.eng.ucsd.edu/">Sugato Basu</a> 
    <a href="https://varunjampani.github.io/">Varun Jampani</a> <br>
    <br>
  <span style="font-size: 24px">Google</span><br />
  
  Accepted in <b>EMNLP 2024 (Industry Track)</b></p>
  <br>
  <img src="./PRISM_files/teaser_image.jpg" class="teaser-gif" style="width:100%;"><br>
  
</div>
  <div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <p>While image-text pre-trained models, such as CLIP, have demonstrated impressive capabilities in learning robust text and image representations, a critical area for substantial improvement remainsâ€”precise color understanding. In this paper, we address this limitation by introducing PRISM, a simple yet highly effective method that extends CLIP's capability to grasp the nuances of precise colors. PRISM seamlessly adapts to both recognized HTML colors and out-of-vocabulary RGB inputs through the utilization of our curated dataset of 100 image-text pairs, which can be effortlessly repurposed for fine-tuning with any desired color. Importantly, PRISM achieves these enhancements without compromising CLIP's performance on established benchmarks. Furthermore, we introduce a novel evaluation framework, ColorLens, featuring both seen and unseen test sets that can be readily repurposed to assess a model's precision in understanding precise colors. Our comprehensive evaluation and results demonstrate significant improvements over baseline models.</p>
</div>

</body>
</html>
